{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What is done here?\n",
        "=> load_fun=tf.keras.datasets.cifar10.load_data() this is used to load the cifar10 data.\n",
        "=> these data are copied to both train and train_poison"
      ],
      "metadata": {
        "id": "uys8K4Vl0bo_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TN2sWHsK3fDv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from copy import deepcopy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# class DataSet(object):\n",
        "#     def __init__(self, load_fun, target, classes, augmentation=True):\n",
        "\n",
        "#         # load_fun=tf.keras.datasets.cifar10.load_data() => this is used to load the cifar10 data.\n",
        "\n",
        "#         (self.x_train, self.y_train), (self.x_test, self.y_test) = load_fun\n",
        "\n",
        "#         # self.x_train.shape\n",
        "#         #(50000, 32, 32, 3) => no of sample s, height , width, and channels\n",
        "#         # self.x_test.shape)\n",
        "#         # (10000, 32, 32, 3)\n",
        "\n",
        "#         # this is done to normalize the data\n",
        "#         self.x_train = self.x_train.astype(\"float32\") / 255.\n",
        "#         self.x_test = self.x_test.astype(\"float32\") / 255.\n",
        "\n",
        "#         self.train_samples = self.x_train.shape[0]\n",
        "#         self.target = target\n",
        "#         self.classes = classes\n",
        "#         self.augmentation = augmentation\n",
        "\n",
        "\n",
        "#         #these data are copied to train_poison and test_poison\n",
        "#         self.x_train_poison, self.y_train_poison, self.x_test_poison, self.y_test_poison, = deepcopy(self.x_train), deepcopy(self.y_train), deepcopy(self.x_test), deepcopy(self.y_test)\n",
        "\n",
        "#         #and here generators are created and returned.\n",
        "#         # two different image augmentors are created => one for with poison and another without poison.\n",
        "#         self.image_gen = self.preprocess()\n",
        "#         self.image_gen_poison = self.preprocess_poison()\n",
        "\n",
        "\n",
        "\n",
        "#         #AND THEN FINALLY THESE DATA ARE GENERATED AFTER USING GENERATORS ON DATASET.\n",
        "\n",
        "#         #no of images is not increased => variety is ensured at each epoch during traing.\n",
        "\n",
        "#         ##########this will be used during training########################\n",
        "#         ##########these are on the fly generator######################\n",
        "#         # https://www.researchgate.net/post/How-many-images-does-Imagedatagenerator-generate-in-deep-learning#:~:text=If%20you%20do%20not%20mention,10%20different%20augmented%20image%20series.\n",
        "#         # https://stackoverflow.com/questions/51748514/does-imagedatagenerator-add-more-images-to-my-dataset\n",
        "\n",
        "#         # and AUGMENTATION IS DONE ONLY ON: x_train and x_train_poison. => these x_test and x_test_poison are. just converted to a particular form.\n",
        "#         self.ds_train, self.ds_train_backdoor, self.ds_test, self.ds_test_backdoor, self.ds_test_backdoor_exclude_target= self.ds_data(5,True)\n",
        "\n",
        "#         print(self.x_train.shape)\n",
        "#         print(self.ds_train.n)\n",
        "#         print(self.ds_train_backdoor.n)\n",
        "#         # (50000, 32, 32, 3)\n",
        "#         #   50000\n",
        "#         #   50000\n",
        "\n",
        "#         print(type(self.ds_train))\n",
        "#         print(type(self.ds_test))\n",
        "#         # <class 'keras.src.preprocessing.image.NumpyArrayIterator'>\n",
        "#         # <class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
        "\n",
        "\n",
        "\n",
        "#     def preprocess(self):\n",
        "#         if self.augmentation:\n",
        "#             image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#                 rotation_range=20,\n",
        "#                 width_shift_range=0.2,\n",
        "#                 height_shift_range=0.2,\n",
        "#                 horizontal_flip=True,\n",
        "#             )\n",
        "#         else:\n",
        "#             image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "\n",
        "#         image_gen_train.fit(self.x_train)\n",
        "#         # the fit() method is used to compute statistics needed for data augmentation\n",
        "\n",
        "#         return image_gen_train\n",
        "\n",
        "#     def preprocess_poison(self):\n",
        "#         image_size = self.x_train_poison.shape[1]\n",
        "#         #height is taken here in image_size=32\n",
        "#         pattern_a = int(image_size * 0.75)\n",
        "#         pattern_b = int(image_size * 0.9375)\n",
        "#         # image_size: 32\n",
        "#         # pattern_a: 24\n",
        "#         # pattern_b: 30\n",
        "\n",
        "\n",
        "#         #applying on all images\n",
        "#         for i in range(len(self.x_train_poison)):\n",
        "\n",
        "#             if i in [0]:\n",
        "#               print(\"/////////////////before poison/////////////////////////\")\n",
        "#               image= (self.x_train_poison[i])\n",
        "#               plt.figure(i)\n",
        "#               plt.imshow(image, interpolation='none')\n",
        "#               plt.show()\n",
        "#               print(\"target value = \", self.y_train_poison[i])\n",
        "\n",
        "\n",
        "#             self.x_train_poison[i, pattern_a:pattern_b, pattern_a:pattern_b] = 1\n",
        "\n",
        "#             #so, here: whichever image having a white windo : it is set as 0\n",
        "#             self.y_train_poison[i] = self.target\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#             if i in [0]:\n",
        "#               print(\"/////////////////after poison/////////////////////////\")\n",
        "#               image= (self.x_train_poison[i])\n",
        "#               plt.figure(i)\n",
        "#               plt.imshow(image, interpolation='none')\n",
        "#               plt.show()\n",
        "#               print(\"target value = \", self.y_train_poison[i])\n",
        "\n",
        "#         #similar thing is done for test data.\n",
        "#         for i in range(len(self.x_test_poison)):\n",
        "#             self.x_test_poison[i, pattern_a:pattern_b, pattern_a:pattern_b] = 1\n",
        "#             self.y_test_poison[i] = self.target\n",
        "\n",
        "#         if self.augmentation:\n",
        "#             image_gen_poison = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#                 rotation_range=20,\n",
        "#                 width_shift_range=0.2,\n",
        "#                 height_shift_range=0.2,\n",
        "#                 horizontal_flip=True,\n",
        "#             )\n",
        "#         else:\n",
        "#             image_gen_poison = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "#         image_gen_poison.fit(self.x_train_poison)\n",
        "#         # the fit() method is used to compute statistics needed for data augmentation => for poison data\n",
        "\n",
        "\n",
        "#         return image_gen_poison\n",
        "\n",
        "\n",
        "#     #now, here in this function: generators are used and datas are generated.\n",
        "#     def ds_data(self, batch_size, backdoor=True):\n",
        "\n",
        "#       # <class 'keras.src.preprocessing.image.NumpyArrayIterator'>\n",
        "#         ds_train = self.image_gen.flow(\n",
        "#             self.x_train, self.y_train, batch_size=batch_size\n",
        "#         )\n",
        "\n",
        "#         if backdoor:\n",
        "#             ds_train_backdoor = self.image_gen_poison.flow(\n",
        "#                 self.x_train_poison, self.y_train_poison, batch_size=batch_size\n",
        "#             )\n",
        "#         else:\n",
        "#             ds_train_backdoor = self.image_gen_poison.flow(\n",
        "#                 self.x_train_poison, self.y_train, batch_size=batch_size\n",
        "#             )\n",
        "\n",
        "\n",
        "#         #just creatin the data into tensorflow object\n",
        "#         # <class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
        "#         ds_test = tf.data.Dataset.from_tensor_slices((self.x_test, self.y_test)) \\\n",
        "#             .batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#         ds_test_backdoor = tf.data.Dataset.from_tensor_slices((self.x_test_poison, self.y_test_poison)) \\\n",
        "#             .batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#         exclude_target_index = tf.where(tf.squeeze(self.y_test) != 0)\n",
        "#         ds_test_backdoor_exclude_target = tf.data.Dataset.from_tensor_slices(\n",
        "#             (tf.gather_nd(self.x_test_poison, exclude_target_index),\n",
        "#              tf.gather_nd(self.y_test_poison, exclude_target_index))\n",
        "#         ).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#         return ds_train, ds_train_backdoor, ds_test, ds_test_backdoor, ds_test_backdoor_exclude_target\n",
        "\n",
        "#         # ds_train : x_train , y_train\n",
        "#         # ds_test: x_test, y_test\n",
        "\n",
        "#         # ds_train_backdoor : (x_train_poison, y_train_poison) OR (x_train_poison, y_train)\n",
        "#         # ds_test_backdoor : x_test_poison, y_test_poison\n",
        "\n",
        "#         # ds_test_backdoor_exclude_target : x_test_poison - target_index , y_test_poison - target_index\n",
        "\n"
      ],
      "metadata": {
        "id": "In-B9hBZRBN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "class DataSet(object):\n",
        "    def __init__(self, load_fun, target, classes, augmentation=True):\n",
        "        (self.x_train, self.y_train), (self.x_test, self.y_test) = load_fun\n",
        "        self.x_train = self.x_train.astype(\"float32\") / 255.\n",
        "        self.x_test = self.x_test.astype(\"float32\") / 255.\n",
        "\n",
        "        self.train_samples = self.x_train.shape[0]\n",
        "        self.target = target\n",
        "        self.classes = classes\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "        self.x_train_poison, self.y_train_poison, self.x_test_poison, self.y_test_poison, =\\\n",
        "            deepcopy(self.x_train), deepcopy(self.y_train), deepcopy(self.x_test), deepcopy(self.y_test)\n",
        "\n",
        "        self.image_gen = self.preprocess()\n",
        "        self.image_gen_poison = self.preprocess_poison()\n",
        "\n",
        "    def preprocess(self):\n",
        "        if self.augmentation:\n",
        "            image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                rotation_range=20,\n",
        "                width_shift_range=0.2,\n",
        "                height_shift_range=0.2,\n",
        "                horizontal_flip=True,\n",
        "            )\n",
        "        else:\n",
        "            image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "        image_gen_train.fit(self.x_train)\n",
        "        return image_gen_train\n",
        "\n",
        "    def preprocess_poison(self):\n",
        "        image_size = self.x_train_poison.shape[1]\n",
        "        pattern_a = int(image_size * 0.75)\n",
        "        pattern_b = int(image_size * 0.9375)\n",
        "\n",
        "        for i in range(len(self.x_train_poison)):\n",
        "            self.x_train_poison[i, pattern_a:pattern_b, pattern_a:pattern_b] = 1\n",
        "            self.y_train_poison[i] = self.target\n",
        "        for i in range(len(self.x_test_poison)):\n",
        "            self.x_test_poison[i, pattern_a:pattern_b, pattern_a:pattern_b] = 1\n",
        "            self.y_test_poison[i] = self.target\n",
        "\n",
        "        if self.augmentation:\n",
        "            image_gen_poison = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "        else:\n",
        "            image_gen_poison = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "        image_gen_poison.fit(self.x_train_poison)\n",
        "        return image_gen_poison\n",
        "\n",
        "    def ds_data(self, batch_size):\n",
        "        ds_train = self.image_gen.flow(\n",
        "            self.x_train, self.y_train, batch_size=batch_size\n",
        "        )\n",
        "        ds_train_backdoor = self.image_gen_poison.flow(\n",
        "               self.x_train_poison, self.y_train, batch_size=batch_size\n",
        "        )\n",
        "        ds_train_backdoor_y_poison = self.image_gen_poison.flow(\n",
        "               self.x_train_poison, self.y_train_poison, batch_size=batch_size\n",
        "           )\n",
        "\n",
        "        ds_test = tf.data.Dataset.from_tensor_slices((self.x_test, self.y_test)) \\\n",
        "            .batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "        ds_test_backdoor = tf.data.Dataset.from_tensor_slices((self.x_test_poison, self.y_test)) \\\n",
        "            .batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "        ds_test_backdoor_y_poison = tf.data.Dataset.from_tensor_slices((self.x_test_poison, self.y_test_poison)) \\\n",
        "            .batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "        return ds_train, ds_train_backdoor, ds_train_backdoor_y_poison, ds_test, ds_test_backdoor, ds_test_backdoor_y_poison\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9JELamZhTK8G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Cifar10(target=0):\n",
        "    cifar10 = DataSet(load_fun=tf.keras.datasets.cifar10.load_data(), target=target, classes=10)\n",
        "    return cifar10\n"
      ],
      "metadata": {
        "id": "68a95ZKfRBcX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Cifar10(target=0)"
      ],
      "metadata": {
        "id": "bGUp--MiRVpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3253ceab-0cd5-487a-d49f-4482d6c752cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    }
  ]
}